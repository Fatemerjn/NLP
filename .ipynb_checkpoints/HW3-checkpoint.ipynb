{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.1-cp312-cp312-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.53.1-cp312-cp312-win_amd64.whl.metadata (165 kB)\n",
      "     ---------------------------------------- 0.0/165.9 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/165.9 kB ? eta -:--:--\n",
      "     --------- --------------------------- 41.0/165.9 kB 487.6 kB/s eta 0:00:01\n",
      "     ------------- ----------------------- 61.4/165.9 kB 656.4 kB/s eta 0:00:01\n",
      "     -------------------- ---------------- 92.2/165.9 kB 744.7 kB/s eta 0:00:01\n",
      "     ------------------------------------ 165.9/165.9 kB 905.1 kB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fateme\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\fateme\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fateme\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.9.1-cp312-cp312-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.0 MB 1.9 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.1/8.0 MB 1.8 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.3/8.0 MB 2.0 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.3/8.0 MB 2.0 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.6/8.0 MB 2.5 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.7/8.0 MB 2.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.9/8.0 MB 3.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.0/8.0 MB 2.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.2/8.0 MB 2.9 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.3/8.0 MB 3.0 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.6/8.0 MB 3.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.7/8.0 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.0/8.0 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.2/8.0 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.5/8.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.7/8.0 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.8/8.0 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.1/8.0 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.3/8.0 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.6/8.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.7/8.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.0/8.0 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.2/8.0 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.4/8.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.6/8.0 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.7/8.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.0/8.0 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.3/8.0 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.6/8.0 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.6/8.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.9/8.0 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.1/8.0 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.5/8.0 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.5/8.0 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.6/8.0 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.0/8.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.3/8.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.4/8.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.5/8.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.0/8.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 4.2 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.2.1-cp312-cp312-win_amd64.whl (189 kB)\n",
      "   ---------------------------------------- 0.0/189.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 189.9/189.9 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.53.1-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.2/2.2 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.2 MB 8.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.2 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.2 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.2 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.2 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.5-cp312-cp312-win_amd64.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.0/56.0 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 0.0/103.2 kB ? eta -:--:--\n",
      "   ------------------------------- -------- 81.9/103.2 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 103.2/103.2 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.53.1 kiwisolver-1.4.5 matplotlib-3.9.1 pyparsing-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n",
      "   ---------------------------------------- 0.0/258.3 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/258.3 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 41.0/258.3 kB 326.8 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 92.2/258.3 kB 581.0 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 92.2/258.3 kB 581.0 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 194.6/258.3 kB 737.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- 258.3/258.3 kB 835.3 kB/s eta 0:00:00\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.3 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main_Genre\n",
      "Drama       610\n",
      "Comedy      234\n",
      "Action      109\n",
      "Thriller     15\n",
      "Romance       9\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/152 [02:54<2:24:47, 58.31s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 203\u001b[0m\n\u001b[0;32m    200\u001b[0m patience_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m--> 203\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m     val_loss, val_accuracy, val_labels, val_preds \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, device)\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 169\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, device)\u001b[0m\n\u001b[0;32m    167\u001b[0m     loss, logits \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[0;32m    168\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m--> 169\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[1;32mc:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Custom BERT Model for Sequence Classification\n",
    "class CustomBertForSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(CustomBertForSequenceClassification, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('HooshvareLab/bert-fa-base-uncased')\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        token_embeddings = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        logits = self.classifier(mean_embeddings)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        return loss, logits\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Filter necessary columns\n",
    "df = df[['Content_1', 'Genre']].dropna()\n",
    "\n",
    "# Define a mapping of similar genres to main genres\n",
    "genre_mapping = {\n",
    "    'Drama': ['Drama', 'Biography', 'Documentary'],\n",
    "    'Comedy': ['Comedy', 'Family', 'Animation'],\n",
    "    'Action': ['Action', 'Adventure', 'Sci-Fi'],\n",
    "    'Romance': ['Romance', 'Musical'],\n",
    "    'Thriller': ['Thriller', 'Horror', 'Mystery']\n",
    "}\n",
    "\n",
    "# Function to map genres to main genres\n",
    "def map_genre(genre):\n",
    "    for main_genre, similar_genres in genre_mapping.items():\n",
    "        if genre in similar_genres:\n",
    "            return main_genre\n",
    "    return None\n",
    "\n",
    "# Apply the mapping\n",
    "df['Main_Genre'] = df['Genre'].apply(map_genre)\n",
    "\n",
    "# Drop rows with unmapped genres\n",
    "df = df.dropna(subset=['Main_Genre'])\n",
    "\n",
    "# Check the new distribution of main genres\n",
    "main_genre_counts = df['Main_Genre'].value_counts()\n",
    "print(main_genre_counts)\n",
    "\n",
    "# Plot the distribution of main genres\n",
    "plt.figure(figsize=(10, 6))\n",
    "main_genre_counts.plot(kind='bar')\n",
    "plt.title('Main Genre Distribution')\n",
    "plt.xlabel('Main Genre')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Convert labels to numerical format\n",
    "label_to_id = {label: idx for idx, label in enumerate(df['Main_Genre'].unique())}\n",
    "id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
    "\n",
    "df['Label'] = df['Main_Genre'].map(label_to_id)\n",
    "\n",
    "# Split into features and labels\n",
    "X = df['Content_1']\n",
    "y = df['Label']\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Tokenize the summaries\n",
    "tokenizer = BertTokenizer.from_pretrained('HooshvareLab/bert-fa-base-uncased')\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    return tokenizer(texts.tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "X_train_encodings = tokenize_texts(X_train)\n",
    "X_val_encodings = tokenize_texts(X_val)\n",
    "X_test_encodings = tokenize_texts(X_test)\n",
    "\n",
    "# Flatten the tokenized data for SMOTE\n",
    "X_train_flat = X_train_encodings['input_ids'].view(len(X_train_encodings['input_ids']), -1).numpy()\n",
    "\n",
    "# Apply SMOTE to balance the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_flat, y_train)\n",
    "\n",
    "# Convert resampled data back to tensors\n",
    "X_train_resampled = torch.tensor(X_train_resampled).view(-1, X_train_encodings['input_ids'].size(1))\n",
    "y_train_resampled = torch.tensor(y_train_resampled.values)\n",
    "\n",
    "# Convert y_train_resampled to Pandas Series to use value_counts\n",
    "y_train_resampled_series = pd.Series(y_train_resampled.numpy())\n",
    "\n",
    "# Calculate class weights\n",
    "class_counts = y_train_resampled_series.value_counts()\n",
    "class_weights = [1.0 / class_counts[label_to_id[label]] for label in df['Main_Genre'].unique()]\n",
    "class_weights = torch.tensor(class_weights, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'), dtype=torch.float32)\n",
    "\n",
    "# Create Dataset class\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Rebuild the encodings dictionary for the resampled data\n",
    "train_encodings_resampled = {\n",
    "    'input_ids': X_train_resampled,\n",
    "    'attention_mask': torch.ones_like(X_train_resampled)  # Assuming all attention masks are 1\n",
    "}\n",
    "\n",
    "train_dataset = MovieDataset(train_encodings_resampled, y_train_resampled)\n",
    "val_dataset = MovieDataset(X_val_encodings, torch.tensor(y_val.values))\n",
    "test_dataset = MovieDataset(X_test_encodings, torch.tensor(y_test.values))\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Load the custom BERT model\n",
    "model = CustomBertForSequenceClassification(num_labels=len(label_to_id))\n",
    "\n",
    "# Ensure all layers are trainable\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Set up optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "# Training function\n",
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        loss, logits = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            loss, logits = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return total_loss / len(val_loader), correct / len(val_loader.dataset), all_labels, all_preds\n",
    "\n",
    "# Training loop with early stopping\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "best_val_accuracy = 0\n",
    "patience = 2\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, device)\n",
    "    val_loss, val_accuracy, val_labels, val_preds = evaluate(model, val_loader, device)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Train loss: {train_loss}\")\n",
    "    print(f\"Validation loss: {val_loss}\")\n",
    "    print(f\"Validation accuracy: {val_accuracy}\")\n",
    "    \n",
    "    # Adjust the learning rate based on the validation loss\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save model if validation accuracy improves\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "        patience_counter = 0\n",
    "   \n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "# Evaluation on Test Set\n",
    "test_loss, test_accuracy, test_labels, test_preds = evaluate(model, test_loader, device)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[id_to_label[i] for i in range(len(label_to_id))])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Function for inference\n",
    "def predict_genre(summary, model, tokenizer, device):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(summary, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, logits = model(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    predicted_class = torch.argmax(probs, dim=-1).item()\n",
    "    return id_to_label[predicted_class]\n",
    "\n",
    "# Example usage\n",
    "summary = \"سالار از طریق چوب بری قاچاق امرار معاش می کند. او یک بار هنگام قطع درخت، دستگیر، اره موتوری اش ضبط و روانه زندان می شود تا دوران محکومیت یک ساله اش را سپری کند. باجی همسر، جلال پسر، ماجان دختر - اعضای خانواده سالار - در غیاب او باید هزینه اره را به صاحب آن میرزا آقا بپردازند. ضمن اینکه ، قبل از واقعه اخیر قرار بوده تا ماجان با لطیف، سرباز اهری پاسگاه روستا ازدواج کند اما بعد از دستگیری سالار، چون باجی، لطیف را هنگام دستگیری شوهرش دیده است، پس در مورد ازدواج لطیف و ماجان تغییر عقیده می دهد. اما لطیف با پیگیری مستمر سعی می کند تا باجی را متقاعد به بی گناهی خود در دستگیری سالار و ازدواج خود با ماجان قانعش کند. جلال که رفتار نامناسب میرزا آقا را با مادرش به خاطر اره ضبط شده، می بیند، با او که رئیس قاچاقچیان چوب جنگل است توافق می کند تا درازای جبران خسارت وی، هر روزه برای فرج و عطا - قاچاقچیان چوب - اره را به میان جنگل ببرد. تحرکات پنهانی و غیبت های مستمر جلال، موجب حساسیت و نگرانی خانواده اش می شود. وقتی ماجان این نگرانی را با لطیف در میان می گذارد، او به تعقیب جلال در یک صبح زود می پردازد، اما لو میرود و توسط قاچاقچیان گرفتار و مورد ضرب و شتم قرار گرفته و جانش را ازدست میدهد. جلال، که در جریان این حادثه به بی گناهی لطیف و خیانت فرج آگاه شده می گریزد. فرج که دریافته او شاهد واقعه بوده، به تعقیبش می پردازد اما او را نمی یابد. باجی و ماجان که از ماوقع آگاه شده اند در جستجوری جلال برمی آیند و او را در درمانگاه روستا با چهره ای سخت پریشان و در هم می یابند، این زمانی است که سالار از زندان آزاد شده و به روستا بازگشته است. او به محض ورود به روستا سراغ لطیف را می گیرد.\"\n",
    "predicted_genre = predict_genre(summary, model, tokenizer, device)\n",
    "print(f\"Predicted genre: {predicted_genre}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
