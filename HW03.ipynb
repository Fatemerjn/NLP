{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.42.3)\n",
      "Requirement already satisfied: torch in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fateme\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\fateme\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Head:\n",
      "                                                 Link            EN_title  \\\n",
      "0  https://www.imvbox.com/watch-persian-movie-ira...   Local Anaesthetic   \n",
      "1  https://www.imvbox.com/watch-persian-movie-ira...         Disturbance   \n",
      "2  https://www.imvbox.com/watch-persian-movie-ira...           Highlight   \n",
      "3  https://www.imvbox.com/watch-persian-movie-ira...               Gilda   \n",
      "4  https://www.imvbox.com/watch-persian-movie-ira...  Atmosphere Station   \n",
      "\n",
      "     PENGLISH_title   PERSIAN_title  \\\n",
      "0  Bi Hessie Mozeie    بی‌حسی موضعی   \n",
      "1         Ashoftegi        آشفته گی   \n",
      "2           Haylayt         هایلایت   \n",
      "3            Geelda           گیلدا   \n",
      "4  Istgahe Atmosfer  ایستگاه اتمسفر   \n",
      "\n",
      "                                           Content_1  \\\n",
      "0  جلال‌، دانشجوی سابق رشته فلسفه، متوجه می‌شود خ...   \n",
      "1  «آشفته‌گی» رئالیستی و اجتماعی نیست. یک فیلم اس...   \n",
      "2  یک تصادف اتومبیل آدم‌هایی را در تقابل با هم قر...   \n",
      "3  گیلدا ماجرای زنی به نام «گیلدا» را روایت می کن...   \n",
      "4  این فیلم روایت گر داستان زندگی زوج جوانی به اس...   \n",
      "\n",
      "                                           Content_2  Score  Year  Genre Time  \n",
      "0  Jalal, a dropouts philosophy student, realizes...    4.8  2018  Drama   73  \n",
      "1  After the murder of his rich twin brother, Bar...    3.8  2018  Crime   78  \n",
      "2  A man and a woman are have a car accident and ...    4.4  2017  Drama   77  \n",
      "3  Gilda who owns a restaurant has a terrible nig...    3.8  2018  Drama   79  \n",
      "4  Vahid and Marjan are a young couple who have g...    5.6  2017  Drama   85  \n",
      "Columns:\n",
      " Index(['Link', 'EN_title', 'PENGLISH_title', 'PERSIAN_title', 'Content_1',\n",
      "       'Content_2', 'Score', 'Year', 'Genre', 'Time'],\n",
      "      dtype='object')\n",
      "Missing Values:\n",
      " Link                0\n",
      "EN_title            0\n",
      "PENGLISH_title      5\n",
      "PERSIAN_title       1\n",
      "Content_1         361\n",
      "Content_2         206\n",
      "Score               0\n",
      "Year                0\n",
      "Genre               0\n",
      "Time                8\n",
      "dtype: int64\n",
      "Cleaned DataFrame Head:\n",
      "                                                 Link            EN_title  \\\n",
      "0  https://www.imvbox.com/watch-persian-movie-ira...   Local Anaesthetic   \n",
      "1  https://www.imvbox.com/watch-persian-movie-ira...         Disturbance   \n",
      "2  https://www.imvbox.com/watch-persian-movie-ira...           Highlight   \n",
      "3  https://www.imvbox.com/watch-persian-movie-ira...               Gilda   \n",
      "4  https://www.imvbox.com/watch-persian-movie-ira...  Atmosphere Station   \n",
      "\n",
      "     PENGLISH_title   PERSIAN_title  \\\n",
      "0  Bi Hessie Mozeie    بی‌حسی موضعی   \n",
      "1         Ashoftegi        آشفته گی   \n",
      "2           Haylayt         هایلایت   \n",
      "3            Geelda           گیلدا   \n",
      "4  Istgahe Atmosfer  ایستگاه اتمسفر   \n",
      "\n",
      "                                           Content_1  \\\n",
      "0  جلال‌، دانشجوی سابق رشته فلسفه، متوجه می‌شود خ...   \n",
      "1  «آشفته‌گی» رئالیستی و اجتماعی نیست. یک فیلم اس...   \n",
      "2  یک تصادف اتومبیل آدم‌هایی را در تقابل با هم قر...   \n",
      "3  گیلدا ماجرای زنی به نام «گیلدا» را روایت می کن...   \n",
      "4  این فیلم روایت گر داستان زندگی زوج جوانی به اس...   \n",
      "\n",
      "                                           Content_2  Score  Year  Genre Time  \n",
      "0  Jalal, a dropouts philosophy student, realizes...    4.8  2018  Drama   73  \n",
      "1  After the murder of his rich twin brother, Bar...    3.8  2018  Crime   78  \n",
      "2  A man and a woman are have a car accident and ...    4.4  2017  Drama   77  \n",
      "3  Gilda who owns a restaurant has a terrible nig...    3.8  2018  Drama   79  \n",
      "4  Vahid and Marjan are a young couple who have g...    5.6  2017  Drama   85  \n",
      "Encoded Labels:\n",
      " 0    7\n",
      "1    5\n",
      "2    7\n",
      "3    7\n",
      "4    7\n",
      "Name: Genre_encoded, dtype: int32\n",
      "Training Set Size: 860\n",
      "Validation Set Size: 108\n",
      "Test Set Size: 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fed91b845a8448398c83de59eb2c1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7875, 'grad_norm': 13.324082374572754, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.09}\n",
      "{'loss': 2.8199, 'grad_norm': 12.376668930053711, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.19}\n",
      "{'loss': 2.5429, 'grad_norm': 10.730721473693848, 'learning_rate': 3e-06, 'epoch': 0.28}\n",
      "{'loss': 2.3365, 'grad_norm': 12.58212661743164, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.37}\n",
      "{'loss': 2.1922, 'grad_norm': 10.538143157958984, 'learning_rate': 5e-06, 'epoch': 0.46}\n",
      "{'loss': 1.9286, 'grad_norm': 11.076147079467773, 'learning_rate': 6e-06, 'epoch': 0.56}\n",
      "{'loss': 1.7189, 'grad_norm': 7.290389060974121, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.65}\n",
      "{'loss': 1.6896, 'grad_norm': 7.394067764282227, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.74}\n",
      "{'loss': 1.6942, 'grad_norm': 6.355474472045898, 'learning_rate': 9e-06, 'epoch': 0.83}\n",
      "{'loss': 1.4974, 'grad_norm': 5.067628383636475, 'learning_rate': 1e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a94d4bdb9c4356b98eb24a73a4a16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3756152391433716, 'eval_runtime': 79.0036, 'eval_samples_per_second': 1.367, 'eval_steps_per_second': 0.177, 'epoch': 1.0}\n",
      "{'loss': 1.6595, 'grad_norm': 4.7327752113342285, 'learning_rate': 1.1000000000000001e-05, 'epoch': 1.02}\n",
      "{'loss': 1.4513, 'grad_norm': 10.303780555725098, 'learning_rate': 1.2e-05, 'epoch': 1.11}\n",
      "{'loss': 1.569, 'grad_norm': 5.351558208465576, 'learning_rate': 1.3000000000000001e-05, 'epoch': 1.2}\n",
      "{'loss': 1.5414, 'grad_norm': 7.159825801849365, 'learning_rate': 1.4000000000000001e-05, 'epoch': 1.3}\n",
      "{'loss': 1.6321, 'grad_norm': 14.174592018127441, 'learning_rate': 1.5e-05, 'epoch': 1.39}\n",
      "{'loss': 1.5092, 'grad_norm': 6.218712329864502, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.48}\n",
      "{'loss': 1.4459, 'grad_norm': 5.7744951248168945, 'learning_rate': 1.7000000000000003e-05, 'epoch': 1.57}\n",
      "{'loss': 1.605, 'grad_norm': 9.15258502960205, 'learning_rate': 1.8e-05, 'epoch': 1.67}\n",
      "{'loss': 1.5618, 'grad_norm': 7.274089813232422, 'learning_rate': 1.9e-05, 'epoch': 1.76}\n",
      "{'loss': 1.4411, 'grad_norm': 7.385501861572266, 'learning_rate': 2e-05, 'epoch': 1.85}\n",
      "{'loss': 1.4361, 'grad_norm': 8.262899398803711, 'learning_rate': 2.1e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f780ce2da2c94c868afd8e8c1ca38f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.289910912513733, 'eval_runtime': 78.0222, 'eval_samples_per_second': 1.384, 'eval_steps_per_second': 0.179, 'epoch': 2.0}\n",
      "{'loss': 1.4517, 'grad_norm': 7.269078731536865, 'learning_rate': 2.2000000000000003e-05, 'epoch': 2.04}\n",
      "{'loss': 1.4696, 'grad_norm': 10.449471473693848, 'learning_rate': 2.3000000000000003e-05, 'epoch': 2.13}\n",
      "{'loss': 1.4095, 'grad_norm': 16.123140335083008, 'learning_rate': 2.4e-05, 'epoch': 2.22}\n",
      "{'loss': 1.4084, 'grad_norm': 8.80736255645752, 'learning_rate': 2.5e-05, 'epoch': 2.31}\n",
      "{'loss': 1.3677, 'grad_norm': 8.909360885620117, 'learning_rate': 2.6000000000000002e-05, 'epoch': 2.41}\n",
      "{'loss': 1.358, 'grad_norm': 9.66272258758545, 'learning_rate': 2.7000000000000002e-05, 'epoch': 2.5}\n",
      "{'loss': 1.1703, 'grad_norm': 11.531188011169434, 'learning_rate': 2.8000000000000003e-05, 'epoch': 2.59}\n",
      "{'loss': 1.3714, 'grad_norm': 8.202092170715332, 'learning_rate': 2.9e-05, 'epoch': 2.69}\n",
      "{'loss': 1.3048, 'grad_norm': 12.660484313964844, 'learning_rate': 3e-05, 'epoch': 2.78}\n",
      "{'loss': 1.4342, 'grad_norm': 11.501770973205566, 'learning_rate': 3.1e-05, 'epoch': 2.87}\n",
      "{'loss': 1.202, 'grad_norm': 17.962291717529297, 'learning_rate': 3.2000000000000005e-05, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c9db4c11f24b1e8de8edb287c3c09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2769464254379272, 'eval_runtime': 78.2225, 'eval_samples_per_second': 1.381, 'eval_steps_per_second': 0.179, 'epoch': 3.0}\n",
      "{'train_runtime': 5050.6151, 'train_samples_per_second': 0.511, 'train_steps_per_second': 0.064, 'train_loss': 1.6508636504043768, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081d5cd89f464245b7365aab139a595b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2469316720962524, 'eval_runtime': 78.4615, 'eval_samples_per_second': 1.376, 'eval_steps_per_second': 0.178, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./parsbert_movie_genre_classifier\\\\tokenizer_config.json',\n",
       " './parsbert_movie_genre_classifier\\\\special_tokens_map.json',\n",
       " './parsbert_movie_genre_classifier\\\\vocab.txt',\n",
       " './parsbert_movie_genre_classifier\\\\added_tokens.json',\n",
       " './parsbert_movie_genre_classifier\\\\tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "dataset_path = 'dataset.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "print(\"DataFrame Head:\\n\", df.head())\n",
    "\n",
    "print(\"Columns:\\n\", df.columns)\n",
    "\n",
    "print(\"Missing Values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Ensure 'Content_1' and 'Genre' columns are present\n",
    "if 'Content_1' not in df.columns or 'Genre' not in df.columns:\n",
    "    raise ValueError(\"Required columns 'Content_1' or 'Genre' are missing in the dataframe.\")\n",
    "\n",
    "# Drop rows with missing 'Content_1' or 'Genre'\n",
    "df = df.dropna(subset=['Content_1', 'Genre'])\n",
    "\n",
    "# Reset index to ensure proper indexing\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows after cleaning\n",
    "print(\"Cleaned DataFrame Head:\\n\", df.head())\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['Genre_encoded'] = label_encoder.fit_transform(df['Genre'])\n",
    "\n",
    "# Display encoded labels\n",
    "print(\"Encoded Labels:\\n\", df['Genre_encoded'].head())\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_df, val_df, test_df = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "# Check the splits\n",
    "print(f\"Training Set Size: {len(train_df)}\")\n",
    "print(f\"Validation Set Size: {len(val_df)}\")\n",
    "print(f\"Test Set Size: {len(test_df)}\")\n",
    "\n",
    "# Initialize ParsBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('HooshvareLab/bert-fa-base-uncased')\n",
    "\n",
    "# Custom dataset class for Persian summaries\n",
    "class PersianMovieGenreDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts.reset_index(drop=True)  # Ensure proper indexing\n",
    "        self.labels = labels.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            text = self.texts.iloc[idx]\n",
    "            label = self.labels.iloc[idx]\n",
    "        except IndexError as e:\n",
    "            print(f\"IndexError: {e}, idx: {idx}, len(texts): {len(self.texts)}, len(labels): {len(self.labels)}\")\n",
    "            raise\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PersianMovieGenreDataset(train_df['Content_1'], train_df['Genre_encoded'], tokenizer)\n",
    "val_dataset = PersianMovieGenreDataset(val_df['Content_1'], val_df['Genre_encoded'], tokenizer)\n",
    "test_dataset = PersianMovieGenreDataset(test_df['Content_1'], test_df['Genre_encoded'], tokenizer)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Load the ParsBERT model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('HooshvareLab/bert-fa-base-uncased', num_labels=len(label_encoder.classes_))\n",
    "model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "results = trainer.evaluate(test_dataset)\n",
    "print(results)\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model.save_pretrained('./parsbert_movie_genre_classifier')\n",
    "tokenizer.save_pretrained('./parsbert_movie_genre_classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0919df5f91c34dac96996c0fd576b723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6388888888888888\n",
      "F1 Score (Macro): 0.212359900373599\n",
      "F1 Score (Micro): 0.6388888888888888\n",
      "Precision (Macro): 0.2773109243697479\n",
      "Recall (Macro): 0.2091723093371347\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  5  0  0  0]\n",
      " [ 0  0  0  0  5  0  0  0]\n",
      " [ 0  0 12  0 11  0  0  0]\n",
      " [ 0  0  2  0  5  0  0  0]\n",
      " [ 0  0  6  0 55  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_true = test_df['Genre_encoded'].to_numpy()\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1 Score (Macro): {f1_macro}')\n",
    "print(f'F1 Score (Micro): {f1_micro}')\n",
    "print(f'Precision (Macro): {precision}')\n",
    "print(f'Recall (Macro): {recall}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted genres: ['Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Comedy', 'Drama']\n",
      "True genres: ['Drama', 'Drama', 'Adventure', 'Romance', 'Drama', 'Drama', 'Fantasy', 'Horror', 'Drama', 'Romance', 'Drama', 'Crime', 'Drama']\n",
      "Number of correct predictions: 7 out of 13\n",
      "Accuracy: 0.54\n"
     ]
    }
   ],
   "source": [
    "# 20 Persian text examples with their true genres\n",
    "examples = [\n",
    "    (\"یک دانشجوی فلسفه متوجه ازدواج پنهانی خواهرش با یک قمارباز می‌شود.\", \"Drama\"),\n",
    "    (\"یک زوج در یک شهر کوچک با مشکلات مالی دست و پنجه نرم می‌کنند.\", \"Drama\"),\n",
    "    (\"یک مرد تنها در تلاش برای بقا در یک جهان پس از آخرالزمان است.\", \"Adventure\"),\n",
    "    (\"یک دختر جوان به دنبال رویاهای خود به یک شهر بزرگ می‌رود.\", \"Romance\"),\n",
    "    (\"یک زن کارآفرین با چالش‌های ایجاد یک شرکت نوپا مواجه می‌شود.\", \"Drama\"),\n",
    "    (\"یک سرباز کهنه‌کار به خانه بازمی‌گردد و با گذشته‌اش مواجه می‌شود.\", \"Drama\"),\n",
    "    (\"یک کودک با نیروهای فوق‌العاده تلاش می‌کند جهان را نجات دهد.\", \"Fantasy\"),\n",
    "    (\"یک خانواده در تلاش برای بقا در یک دنیای زامبی‌ها هستند.\", \"Horror\"),\n",
    "    (\"یک هنرمند جوان تلاش می‌کند در دنیای هنر معروف شود.\", \"Drama\"),\n",
    "    (\"یک زوج عاشق با چالش‌های خانوادگی مواجه می‌شوند.\", \"Romance\"),\n",
    "    (\"یک گروه موسیقی جوان تلاش می‌کنند در صنعت موسیقی موفق شوند.\", \"Drama\"),\n",
    "    (\"یک وکیل تلاش می‌کند یک پرونده جنایی بزرگ را حل کند.\", \"Crime\"),\n",
    "    (\"یک نویسنده معروف با بحران خلاقیت مواجه می‌شود.\", \"Drama\"),\n",
    "]\n",
    "\n",
    "# Define the prediction function\n",
    "def predict_genre(text, model, tokenizer):\n",
    "    model.eval()\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predicted_class_idx = logits.argmax(axis=1).item()\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_class_idx])[0]\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "# Predict genres for the examples\n",
    "true_labels = [genre for _, genre in examples]\n",
    "predicted_labels = [predict_genre(text, model, tokenizer) for text, _ in examples]\n",
    "\n",
    "# Evaluate accuracy\n",
    "correct_predictions = sum([true == pred for true, pred in zip(true_labels, predicted_labels)])\n",
    "accuracy = correct_predictions / len(examples)\n",
    "\n",
    "print(f'Predicted genres: {predicted_labels}')\n",
    "print(f'True genres: {true_labels}')\n",
    "print(f'Number of correct predictions: {correct_predictions} out of {len(examples)}')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 Persian text examples with their true genres\n",
    "examples = [\n",
    "    (\"سارا در تلاش است تا با مدیریت بحران‌های خانوادگی و مشکلات شخصی‌اش زندگی بهتری برای فرزندانش فراهم کند.\", \"Drama\"),\n",
    "    (\"کامران تصمیم می‌گیرد که پس از بازنشستگی به شهر زادگاهش بازگردد و خانه کودکی‌اش را بازسازی کند.\", \"Drama\"),\n",
    "    (\"یک کمدین جوان در تلاش است تا با شوخی‌های نوین و خلاقانه خود مخاطبان بیشتری جذب کند.\", \"Comedy\"),\n",
    "    (\"یک معلم مدرسه روستایی تلاش می‌کند تا دانش‌آموزانش را به یادگیری تشویق کند و آینده بهتری برای آنها رقم بزند.\", \"Drama\"),\n",
    "    (\"مریم و علی تصمیم می‌گیرند که در یک سفر ماجراجویانه به کوه‌های شمال کشور بروند و در این سفر با اتفاقات خنده‌داری مواجه می‌شوند.\", \"Comedy\"),\n",
    "    (\"یک نویسنده تلاش می‌کند تا از داستان‌های واقعی زندگی مردم یک کتاب الهام‌بخش بنویسد.\", \"Drama\"),\n",
    "    (\"یک گروه موسیقی تصمیم می‌گیرند تا در یک فستیوال بزرگ شرکت کنند و در این راه با مشکلات و اتفاقات خنده‌داری روبرو می‌شوند.\", \"Comedy\"),\n",
    "    (\"یک بازیگر مشهور با چالش‌های شهرت و فشارهای اجتماعی روبرو می‌شود و تلاش می‌کند تا زندگی شخصی‌اش را مدیریت کند.\", \"Drama\"),\n",
    "    (\"یک پسر نوجوان که به تازگی وارد دبیرستان شده است با مشکلات جدید و چالش‌های بلوغ مواجه می‌شود.\", \"Drama\"),\n",
    "    (\"یک زن و شوهر تصمیم می‌گیرند تا کسب و کار خانوادگی خود را گسترش دهند و در این راه با مشکلات خنده‌داری روبرو می‌شوند.\", \"Comedy\"),\n",
    "    (\"یک زن جوان تصمیم می‌گیرد که پس از شکست عشقی بزرگ به سفر برود و در این سفر با خودآگاهی بیشتری روبرو شود.\", \"Drama\"),\n",
    "    (\"یک پدر تنها تلاش می‌کند تا برای دختر کوچکش یک جشن تولد فراموش‌نشدنی برگزار کند.\", \"Drama\"),\n",
    "    (\"یک کارآگاه خصوصی در تلاش است تا پرونده پیچیده یک قتل را حل کند.\", \"Drama\"),\n",
    "    (\"یک استاد دانشگاه تلاش می‌کند تا با تحقیقاتی جدید و خلاقانه در حوزه علمی خود پیشرفت کند.\", \"Drama\"),\n",
    "    (\"یک زن جوان در تلاش است تا یک شرکت استارتاپی موفق راه‌اندازی کند و با مشکلات زیادی مواجه می‌شود.\", \"Drama\"),\n",
    "    (\"یک گروه از دوستان تصمیم می‌گیرند که تعطیلات خود را در یک ویلا در شمال کشور بگذرانند و با ماجراهای خنده‌داری مواجه می‌شوند.\", \"Comedy\"),\n",
    "    (\"یک هنرمند جوان در تلاش است تا اولین نمایشگاه هنری خود را با موفقیت برگزار کند.\", \"Drama\"),\n",
    "    (\"یک مربی فوتبال تلاش می‌کند تا تیم جوانان محلی را به قهرمانی برساند.\", \"Drama\"),\n",
    "    (\"یک زوج مسن تصمیم می‌گیرند تا باقی‌مانده زندگی خود را به سفرهای مختلف بگذرانند و در هر سفر با اتفاقات خنده‌داری مواجه می‌شوند.\", \"Comedy\"),\n",
    "    (\"یک مخترع جوان در تلاش است تا ایده‌های نوآورانه خود را به واقعیت تبدیل کند.\", \"Drama\"),\n",
    "    (\"یک دختر جوان که به تازگی از دانشگاه فارغ‌التحصیل شده است، تلاش می‌کند تا شغلی مناسب پیدا کند.\", \"Drama\"),\n",
    "    (\"یک نویسنده در تلاش است تا با الهام از زندگی خود یک رمان پرفروش بنویسد.\", \"Drama\"),\n",
    "    (\"یک گروه از دوستان تصمیم می‌گیرند که یک رستوران کوچک افتتاح کنند و در این راه با چالش‌های خنده‌داری روبرو می‌شوند.\", \"Comedy\"),\n",
    "    (\"یک مادر جوان تلاش می‌کند تا همزمان با مدیریت خانه و شغل، از کودکانش مراقبت کند.\", \"Drama\"),\n",
    "    (\"یک معلم موسیقی در تلاش است تا استعدادهای نهفته دانش‌آموزانش را کشف و پرورش دهد.\", \"Drama\"),\n",
    "    (\"یک زن تصمیم می‌گیرد تا پس از جدایی از همسرش، زندگی جدیدی را آغاز کند.\", \"Drama\"),\n",
    "    (\"یک گروه تئاتر آماتور در تلاش است تا یک نمایش بزرگ را روی صحنه ببرند و با مشکلات و ماجراهای خنده‌داری روبرو می‌شوند.\", \"Comedy\"),\n",
    "    (\"یک پسر نوجوان که به تازگی به شهر جدیدی نقل مکان کرده است، تلاش می‌کند تا دوستان جدید پیدا کند.\", \"Drama\"),\n",
    "    (\"یک ورزشکار جوان تلاش می‌کند تا به تیم ملی کشورش راه پیدا کند و در این راه با چالش‌های زیادی روبرو می‌شود.\", \"Drama\"),\n",
    "    (\"یک زن و مرد در یک ماجرای عشقی پیچیده قرار می‌گیرند و تلاش می‌کنند تا موانع را پشت سر بگذارند.\", \"Drama\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genre(text, model, tokenizer):\n",
    "    model.eval()\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predicted_class_idx = logits.argmax(axis=1).item()\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_class_idx])[0]\n",
    "    \n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted genres: ['Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama']\n",
      "True genres: ['Drama', 'Drama', 'Comedy', 'Drama', 'Comedy', 'Drama', 'Comedy', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama']\n",
      "Number of correct predictions: 28 out of 30\n",
      "Accuracy: 0.93\n",
      "F1 Score (Macro): 0.91\n",
      "F1 Score (Micro): 0.93\n",
      "Precision (Macro): 0.91\n",
      "Recall (Macro): 0.91\n",
      "Confusion Matrix:\n",
      "[[ 7  1]\n",
      " [ 1 21]]\n"
     ]
    }
   ],
   "source": [
    "# Predict genres for the examples\n",
    "true_labels = [genre for _, genre in examples]\n",
    "predicted_labels = [predict_genre(text, model, tokenizer) for text, _ in examples]\n",
    "\n",
    "# Evaluate accuracy\n",
    "correct_predictions = sum([true == pred for true, pred in zip(true_labels, predicted_labels)])\n",
    "accuracy = correct_predictions / len(examples)\n",
    "\n",
    "print(f'Predicted genres: {predicted_labels}')\n",
    "print(f'True genres: {true_labels}')\n",
    "print(f'Number of correct predictions: {correct_predictions} out of {len(examples)}')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Calculate and print additional metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "f1_macro = f1_score(true_labels, predicted_labels, average='macro')\n",
    "f1_micro = f1_score(true_labels, predicted_labels, average='micro')\n",
    "precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "print(f'F1 Score (Macro): {f1_macro:.2f}')\n",
    "print(f'F1 Score (Micro): {f1_micro:.2f}')\n",
    "print(f'Precision (Macro): {precision:.2f}')\n",
    "print(f'Recall (Macro): {recall:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
