{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.42.3)\n",
      "Requirement already satisfied: torch in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fateme\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\fateme\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\fateme\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Head:\n",
      "                                                 Link            EN_title  \\\n",
      "0  https://www.imvbox.com/watch-persian-movie-ira...   Local Anaesthetic   \n",
      "1  https://www.imvbox.com/watch-persian-movie-ira...         Disturbance   \n",
      "2  https://www.imvbox.com/watch-persian-movie-ira...           Highlight   \n",
      "3  https://www.imvbox.com/watch-persian-movie-ira...               Gilda   \n",
      "4  https://www.imvbox.com/watch-persian-movie-ira...  Atmosphere Station   \n",
      "\n",
      "     PENGLISH_title   PERSIAN_title  \\\n",
      "0  Bi Hessie Mozeie    Ø¨ÛŒâ€ŒØ­Ø³ÛŒ Ù…ÙˆØ¶Ø¹ÛŒ   \n",
      "1         Ashoftegi        Ø¢Ø´ÙØªÙ‡ Ú¯ÛŒ   \n",
      "2           Haylayt         Ù‡Ø§ÛŒÙ„Ø§ÛŒØª   \n",
      "3            Geelda           Ú¯ÛŒÙ„Ø¯Ø§   \n",
      "4  Istgahe Atmosfer  Ø§ÛŒØ³ØªÚ¯Ø§Ù‡ Ø§ØªÙ…Ø³ÙØ±   \n",
      "\n",
      "                                           Content_1  \\\n",
      "0  Ø¬Ù„Ø§Ù„â€ŒØŒ Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒ Ø³Ø§Ø¨Ù‚ Ø±Ø´ØªÙ‡ ÙÙ„Ø³ÙÙ‡ØŒ Ù…ØªÙˆØ¬Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø®...   \n",
      "1  Â«Ø¢Ø´ÙØªÙ‡â€ŒÚ¯ÛŒÂ» Ø±Ø¦Ø§Ù„ÛŒØ³ØªÛŒ Ùˆ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ù†ÛŒØ³Øª. ÛŒÚ© ÙÛŒÙ„Ù… Ø§Ø³...   \n",
      "2  ÛŒÚ© ØªØµØ§Ø¯Ù Ø§ØªÙˆÙ…Ø¨ÛŒÙ„ Ø¢Ø¯Ù…â€ŒÙ‡Ø§ÛŒÛŒ Ø±Ø§ Ø¯Ø± ØªÙ‚Ø§Ø¨Ù„ Ø¨Ø§ Ù‡Ù… Ù‚Ø±...   \n",
      "3  Ú¯ÛŒÙ„Ø¯Ø§ Ù…Ø§Ø¬Ø±Ø§ÛŒ Ø²Ù†ÛŒ Ø¨Ù‡ Ù†Ø§Ù… Â«Ú¯ÛŒÙ„Ø¯Ø§Â» Ø±Ø§ Ø±ÙˆØ§ÛŒØª Ù…ÛŒ Ú©Ù†...   \n",
      "4  Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø±ÙˆØ§ÛŒØª Ú¯Ø± Ø¯Ø§Ø³ØªØ§Ù† Ø²Ù†Ø¯Ú¯ÛŒ Ø²ÙˆØ¬ Ø¬ÙˆØ§Ù†ÛŒ Ø¨Ù‡ Ø§Ø³...   \n",
      "\n",
      "                                           Content_2  Score  Year  Genre Time  \n",
      "0  Jalal, a dropouts philosophy student, realizes...    4.8  2018  Drama   73  \n",
      "1  After the murder of his rich twin brother, Bar...    3.8  2018  Crime   78  \n",
      "2  A man and a woman are have a car accident and ...    4.4  2017  Drama   77  \n",
      "3  Gilda who owns a restaurant has a terrible nig...    3.8  2018  Drama   79  \n",
      "4  Vahid and Marjan are a young couple who have g...    5.6  2017  Drama   85  \n",
      "Columns:\n",
      " Index(['Link', 'EN_title', 'PENGLISH_title', 'PERSIAN_title', 'Content_1',\n",
      "       'Content_2', 'Score', 'Year', 'Genre', 'Time'],\n",
      "      dtype='object')\n",
      "Missing Values:\n",
      " Link                0\n",
      "EN_title            0\n",
      "PENGLISH_title      5\n",
      "PERSIAN_title       1\n",
      "Content_1         361\n",
      "Content_2         206\n",
      "Score               0\n",
      "Year                0\n",
      "Genre               0\n",
      "Time                8\n",
      "dtype: int64\n",
      "Cleaned DataFrame Head:\n",
      "                                                 Link            EN_title  \\\n",
      "0  https://www.imvbox.com/watch-persian-movie-ira...   Local Anaesthetic   \n",
      "1  https://www.imvbox.com/watch-persian-movie-ira...         Disturbance   \n",
      "2  https://www.imvbox.com/watch-persian-movie-ira...           Highlight   \n",
      "3  https://www.imvbox.com/watch-persian-movie-ira...               Gilda   \n",
      "4  https://www.imvbox.com/watch-persian-movie-ira...  Atmosphere Station   \n",
      "\n",
      "     PENGLISH_title   PERSIAN_title  \\\n",
      "0  Bi Hessie Mozeie    Ø¨ÛŒâ€ŒØ­Ø³ÛŒ Ù…ÙˆØ¶Ø¹ÛŒ   \n",
      "1         Ashoftegi        Ø¢Ø´ÙØªÙ‡ Ú¯ÛŒ   \n",
      "2           Haylayt         Ù‡Ø§ÛŒÙ„Ø§ÛŒØª   \n",
      "3            Geelda           Ú¯ÛŒÙ„Ø¯Ø§   \n",
      "4  Istgahe Atmosfer  Ø§ÛŒØ³ØªÚ¯Ø§Ù‡ Ø§ØªÙ…Ø³ÙØ±   \n",
      "\n",
      "                                           Content_1  \\\n",
      "0  Ø¬Ù„Ø§Ù„â€ŒØŒ Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒ Ø³Ø§Ø¨Ù‚ Ø±Ø´ØªÙ‡ ÙÙ„Ø³ÙÙ‡ØŒ Ù…ØªÙˆØ¬Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø®...   \n",
      "1  Â«Ø¢Ø´ÙØªÙ‡â€ŒÚ¯ÛŒÂ» Ø±Ø¦Ø§Ù„ÛŒØ³ØªÛŒ Ùˆ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ù†ÛŒØ³Øª. ÛŒÚ© ÙÛŒÙ„Ù… Ø§Ø³...   \n",
      "2  ÛŒÚ© ØªØµØ§Ø¯Ù Ø§ØªÙˆÙ…Ø¨ÛŒÙ„ Ø¢Ø¯Ù…â€ŒÙ‡Ø§ÛŒÛŒ Ø±Ø§ Ø¯Ø± ØªÙ‚Ø§Ø¨Ù„ Ø¨Ø§ Ù‡Ù… Ù‚Ø±...   \n",
      "3  Ú¯ÛŒÙ„Ø¯Ø§ Ù…Ø§Ø¬Ø±Ø§ÛŒ Ø²Ù†ÛŒ Ø¨Ù‡ Ù†Ø§Ù… Â«Ú¯ÛŒÙ„Ø¯Ø§Â» Ø±Ø§ Ø±ÙˆØ§ÛŒØª Ù…ÛŒ Ú©Ù†...   \n",
      "4  Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø±ÙˆØ§ÛŒØª Ú¯Ø± Ø¯Ø§Ø³ØªØ§Ù† Ø²Ù†Ø¯Ú¯ÛŒ Ø²ÙˆØ¬ Ø¬ÙˆØ§Ù†ÛŒ Ø¨Ù‡ Ø§Ø³...   \n",
      "\n",
      "                                           Content_2  Score  Year  Genre Time  \n",
      "0  Jalal, a dropouts philosophy student, realizes...    4.8  2018  Drama   73  \n",
      "1  After the murder of his rich twin brother, Bar...    3.8  2018  Crime   78  \n",
      "2  A man and a woman are have a car accident and ...    4.4  2017  Drama   77  \n",
      "3  Gilda who owns a restaurant has a terrible nig...    3.8  2018  Drama   79  \n",
      "4  Vahid and Marjan are a young couple who have g...    5.6  2017  Drama   85  \n",
      "Encoded Labels:\n",
      " 0    7\n",
      "1    5\n",
      "2    7\n",
      "3    7\n",
      "4    7\n",
      "Name: Genre_encoded, dtype: int32\n",
      "Training Set Size: 860\n",
      "Validation Set Size: 108\n",
      "Test Set Size: 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fed91b845a8448398c83de59eb2c1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7875, 'grad_norm': 13.324082374572754, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.09}\n",
      "{'loss': 2.8199, 'grad_norm': 12.376668930053711, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.19}\n",
      "{'loss': 2.5429, 'grad_norm': 10.730721473693848, 'learning_rate': 3e-06, 'epoch': 0.28}\n",
      "{'loss': 2.3365, 'grad_norm': 12.58212661743164, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.37}\n",
      "{'loss': 2.1922, 'grad_norm': 10.538143157958984, 'learning_rate': 5e-06, 'epoch': 0.46}\n",
      "{'loss': 1.9286, 'grad_norm': 11.076147079467773, 'learning_rate': 6e-06, 'epoch': 0.56}\n",
      "{'loss': 1.7189, 'grad_norm': 7.290389060974121, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.65}\n",
      "{'loss': 1.6896, 'grad_norm': 7.394067764282227, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.74}\n",
      "{'loss': 1.6942, 'grad_norm': 6.355474472045898, 'learning_rate': 9e-06, 'epoch': 0.83}\n",
      "{'loss': 1.4974, 'grad_norm': 5.067628383636475, 'learning_rate': 1e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a94d4bdb9c4356b98eb24a73a4a16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3756152391433716, 'eval_runtime': 79.0036, 'eval_samples_per_second': 1.367, 'eval_steps_per_second': 0.177, 'epoch': 1.0}\n",
      "{'loss': 1.6595, 'grad_norm': 4.7327752113342285, 'learning_rate': 1.1000000000000001e-05, 'epoch': 1.02}\n",
      "{'loss': 1.4513, 'grad_norm': 10.303780555725098, 'learning_rate': 1.2e-05, 'epoch': 1.11}\n",
      "{'loss': 1.569, 'grad_norm': 5.351558208465576, 'learning_rate': 1.3000000000000001e-05, 'epoch': 1.2}\n",
      "{'loss': 1.5414, 'grad_norm': 7.159825801849365, 'learning_rate': 1.4000000000000001e-05, 'epoch': 1.3}\n",
      "{'loss': 1.6321, 'grad_norm': 14.174592018127441, 'learning_rate': 1.5e-05, 'epoch': 1.39}\n",
      "{'loss': 1.5092, 'grad_norm': 6.218712329864502, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.48}\n",
      "{'loss': 1.4459, 'grad_norm': 5.7744951248168945, 'learning_rate': 1.7000000000000003e-05, 'epoch': 1.57}\n",
      "{'loss': 1.605, 'grad_norm': 9.15258502960205, 'learning_rate': 1.8e-05, 'epoch': 1.67}\n",
      "{'loss': 1.5618, 'grad_norm': 7.274089813232422, 'learning_rate': 1.9e-05, 'epoch': 1.76}\n",
      "{'loss': 1.4411, 'grad_norm': 7.385501861572266, 'learning_rate': 2e-05, 'epoch': 1.85}\n",
      "{'loss': 1.4361, 'grad_norm': 8.262899398803711, 'learning_rate': 2.1e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f780ce2da2c94c868afd8e8c1ca38f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.289910912513733, 'eval_runtime': 78.0222, 'eval_samples_per_second': 1.384, 'eval_steps_per_second': 0.179, 'epoch': 2.0}\n",
      "{'loss': 1.4517, 'grad_norm': 7.269078731536865, 'learning_rate': 2.2000000000000003e-05, 'epoch': 2.04}\n",
      "{'loss': 1.4696, 'grad_norm': 10.449471473693848, 'learning_rate': 2.3000000000000003e-05, 'epoch': 2.13}\n",
      "{'loss': 1.4095, 'grad_norm': 16.123140335083008, 'learning_rate': 2.4e-05, 'epoch': 2.22}\n",
      "{'loss': 1.4084, 'grad_norm': 8.80736255645752, 'learning_rate': 2.5e-05, 'epoch': 2.31}\n",
      "{'loss': 1.3677, 'grad_norm': 8.909360885620117, 'learning_rate': 2.6000000000000002e-05, 'epoch': 2.41}\n",
      "{'loss': 1.358, 'grad_norm': 9.66272258758545, 'learning_rate': 2.7000000000000002e-05, 'epoch': 2.5}\n",
      "{'loss': 1.1703, 'grad_norm': 11.531188011169434, 'learning_rate': 2.8000000000000003e-05, 'epoch': 2.59}\n",
      "{'loss': 1.3714, 'grad_norm': 8.202092170715332, 'learning_rate': 2.9e-05, 'epoch': 2.69}\n",
      "{'loss': 1.3048, 'grad_norm': 12.660484313964844, 'learning_rate': 3e-05, 'epoch': 2.78}\n",
      "{'loss': 1.4342, 'grad_norm': 11.501770973205566, 'learning_rate': 3.1e-05, 'epoch': 2.87}\n",
      "{'loss': 1.202, 'grad_norm': 17.962291717529297, 'learning_rate': 3.2000000000000005e-05, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c9db4c11f24b1e8de8edb287c3c09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2769464254379272, 'eval_runtime': 78.2225, 'eval_samples_per_second': 1.381, 'eval_steps_per_second': 0.179, 'epoch': 3.0}\n",
      "{'train_runtime': 5050.6151, 'train_samples_per_second': 0.511, 'train_steps_per_second': 0.064, 'train_loss': 1.6508636504043768, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081d5cd89f464245b7365aab139a595b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2469316720962524, 'eval_runtime': 78.4615, 'eval_samples_per_second': 1.376, 'eval_steps_per_second': 0.178, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./parsbert_movie_genre_classifier\\\\tokenizer_config.json',\n",
       " './parsbert_movie_genre_classifier\\\\special_tokens_map.json',\n",
       " './parsbert_movie_genre_classifier\\\\vocab.txt',\n",
       " './parsbert_movie_genre_classifier\\\\added_tokens.json',\n",
       " './parsbert_movie_genre_classifier\\\\tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "dataset_path = 'dataset.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "print(\"DataFrame Head:\\n\", df.head())\n",
    "\n",
    "print(\"Columns:\\n\", df.columns)\n",
    "\n",
    "print(\"Missing Values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Ensure 'Content_1' and 'Genre' columns are present\n",
    "if 'Content_1' not in df.columns or 'Genre' not in df.columns:\n",
    "    raise ValueError(\"Required columns 'Content_1' or 'Genre' are missing in the dataframe.\")\n",
    "\n",
    "# Drop rows with missing 'Content_1' or 'Genre'\n",
    "df = df.dropna(subset=['Content_1', 'Genre'])\n",
    "\n",
    "# Reset index to ensure proper indexing\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows after cleaning\n",
    "print(\"Cleaned DataFrame Head:\\n\", df.head())\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['Genre_encoded'] = label_encoder.fit_transform(df['Genre'])\n",
    "\n",
    "# Display encoded labels\n",
    "print(\"Encoded Labels:\\n\", df['Genre_encoded'].head())\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_df, val_df, test_df = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "# Check the splits\n",
    "print(f\"Training Set Size: {len(train_df)}\")\n",
    "print(f\"Validation Set Size: {len(val_df)}\")\n",
    "print(f\"Test Set Size: {len(test_df)}\")\n",
    "\n",
    "# Initialize ParsBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('HooshvareLab/bert-fa-base-uncased')\n",
    "\n",
    "# Custom dataset class for Persian summaries\n",
    "class PersianMovieGenreDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts.reset_index(drop=True)  # Ensure proper indexing\n",
    "        self.labels = labels.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            text = self.texts.iloc[idx]\n",
    "            label = self.labels.iloc[idx]\n",
    "        except IndexError as e:\n",
    "            print(f\"IndexError: {e}, idx: {idx}, len(texts): {len(self.texts)}, len(labels): {len(self.labels)}\")\n",
    "            raise\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PersianMovieGenreDataset(train_df['Content_1'], train_df['Genre_encoded'], tokenizer)\n",
    "val_dataset = PersianMovieGenreDataset(val_df['Content_1'], val_df['Genre_encoded'], tokenizer)\n",
    "test_dataset = PersianMovieGenreDataset(test_df['Content_1'], test_df['Genre_encoded'], tokenizer)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Load the ParsBERT model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('HooshvareLab/bert-fa-base-uncased', num_labels=len(label_encoder.classes_))\n",
    "model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "results = trainer.evaluate(test_dataset)\n",
    "print(results)\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model.save_pretrained('./parsbert_movie_genre_classifier')\n",
    "tokenizer.save_pretrained('./parsbert_movie_genre_classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0919df5f91c34dac96996c0fd576b723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6388888888888888\n",
      "F1 Score (Macro): 0.212359900373599\n",
      "F1 Score (Micro): 0.6388888888888888\n",
      "Precision (Macro): 0.2773109243697479\n",
      "Recall (Macro): 0.2091723093371347\n",
      "Confusion Matrix:\n",
      "[[ 2  0  1  0  5  0  0  0]\n",
      " [ 0  0  0  0  5  0  0  0]\n",
      " [ 0  0 12  0 11  0  0  0]\n",
      " [ 0  0  2  0  5  0  0  0]\n",
      " [ 0  0  6  0 55  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_true = test_df['Genre_encoded'].to_numpy()\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1 Score (Macro): {f1_macro}')\n",
    "print(f'F1 Score (Micro): {f1_micro}')\n",
    "print(f'Precision (Macro): {precision}')\n",
    "print(f'Recall (Macro): {recall}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted genres: ['Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Comedy', 'Drama']\n",
      "True genres: ['Drama', 'Drama', 'Adventure', 'Romance', 'Drama', 'Drama', 'Fantasy', 'Horror', 'Drama', 'Romance', 'Drama', 'Crime', 'Drama']\n",
      "Number of correct predictions: 7 out of 13\n",
      "Accuracy: 0.54\n"
     ]
    }
   ],
   "source": [
    "# 20 Persian text examples with their true genres\n",
    "examples = [\n",
    "    (\"ÛŒÚ© Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒ ÙÙ„Ø³ÙÙ‡ Ù…ØªÙˆØ¬Ù‡ Ø§Ø²Ø¯ÙˆØ§Ø¬ Ù¾Ù†Ù‡Ø§Ù†ÛŒ Ø®ÙˆØ§Ù‡Ø±Ø´ Ø¨Ø§ ÛŒÚ© Ù‚Ù…Ø§Ø±Ø¨Ø§Ø² Ù…ÛŒâ€ŒØ´ÙˆØ¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ø²ÙˆØ¬ Ø¯Ø± ÛŒÚ© Ø´Ù‡Ø± Ú©ÙˆÚ†Ú© Ø¨Ø§ Ù…Ø´Ú©Ù„Ø§Øª Ù…Ø§Ù„ÛŒ Ø¯Ø³Øª Ùˆ Ù¾Ù†Ø¬Ù‡ Ù†Ø±Ù… Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ù…Ø±Ø¯ ØªÙ†Ù‡Ø§ Ø¯Ø± ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ù‚Ø§ Ø¯Ø± ÛŒÚ© Ø¬Ù‡Ø§Ù† Ù¾Ø³ Ø§Ø² Ø¢Ø®Ø±Ø§Ù„Ø²Ù…Ø§Ù† Ø§Ø³Øª.\", \"Adventure\"),\n",
    "    (\"ÛŒÚ© Ø¯Ø®ØªØ± Ø¬ÙˆØ§Ù† Ø¨Ù‡ Ø¯Ù†Ø¨Ø§Ù„ Ø±ÙˆÛŒØ§Ù‡Ø§ÛŒ Ø®ÙˆØ¯ Ø¨Ù‡ ÛŒÚ© Ø´Ù‡Ø± Ø¨Ø²Ø±Ú¯ Ù…ÛŒâ€ŒØ±ÙˆØ¯.\", \"Romance\"),\n",
    "    (\"ÛŒÚ© Ø²Ù† Ú©Ø§Ø±Ø¢ÙØ±ÛŒÙ† Ø¨Ø§ Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© Ø´Ø±Ú©Øª Ù†ÙˆÙ¾Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ø³Ø±Ø¨Ø§Ø² Ú©Ù‡Ù†Ù‡â€ŒÚ©Ø§Ø± Ø¨Ù‡ Ø®Ø§Ù†Ù‡ Ø¨Ø§Ø²Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø¯ Ùˆ Ø¨Ø§ Ú¯Ø°Ø´ØªÙ‡â€ŒØ§Ø´ Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ú©ÙˆØ¯Ú© Ø¨Ø§ Ù†ÛŒØ±ÙˆÙ‡Ø§ÛŒ ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ø¬Ù‡Ø§Ù† Ø±Ø§ Ù†Ø¬Ø§Øª Ø¯Ù‡Ø¯.\", \"Fantasy\"),\n",
    "    (\"ÛŒÚ© Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡ Ø¯Ø± ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ù‚Ø§ Ø¯Ø± ÛŒÚ© Ø¯Ù†ÛŒØ§ÛŒ Ø²Ø§Ù…Ø¨ÛŒâ€ŒÙ‡Ø§ Ù‡Ø³ØªÙ†Ø¯.\", \"Horror\"),\n",
    "    (\"ÛŒÚ© Ù‡Ù†Ø±Ù…Ù†Ø¯ Ø¬ÙˆØ§Ù† ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ø¯Ø± Ø¯Ù†ÛŒØ§ÛŒ Ù‡Ù†Ø± Ù…Ø¹Ø±ÙˆÙ Ø´ÙˆØ¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ø²ÙˆØ¬ Ø¹Ø§Ø´Ù‚ Ø¨Ø§ Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.\", \"Romance\"),\n",
    "    (\"ÛŒÚ© Ú¯Ø±ÙˆÙ‡ Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø¬ÙˆØ§Ù† ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ Ø¯Ø± ØµÙ†Ø¹Øª Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ù…ÙˆÙÙ‚ Ø´ÙˆÙ†Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© ÙˆÚ©ÛŒÙ„ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ÛŒÚ© Ù¾Ø±ÙˆÙ†Ø¯Ù‡ Ø¬Ù†Ø§ÛŒÛŒ Ø¨Ø²Ø±Ú¯ Ø±Ø§ Ø­Ù„ Ú©Ù†Ø¯.\", \"Crime\"),\n",
    "    (\"ÛŒÚ© Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ù…Ø¹Ø±ÙˆÙ Ø¨Ø§ Ø¨Ø­Ø±Ø§Ù† Ø®Ù„Ø§Ù‚ÛŒØª Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\", \"Drama\"),\n",
    "]\n",
    "\n",
    "# Define the prediction function\n",
    "def predict_genre(text, model, tokenizer):\n",
    "    model.eval()\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predicted_class_idx = logits.argmax(axis=1).item()\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_class_idx])[0]\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "# Predict genres for the examples\n",
    "true_labels = [genre for _, genre in examples]\n",
    "predicted_labels = [predict_genre(text, model, tokenizer) for text, _ in examples]\n",
    "\n",
    "# Evaluate accuracy\n",
    "correct_predictions = sum([true == pred for true, pred in zip(true_labels, predicted_labels)])\n",
    "accuracy = correct_predictions / len(examples)\n",
    "\n",
    "print(f'Predicted genres: {predicted_labels}')\n",
    "print(f'True genres: {true_labels}')\n",
    "print(f'Number of correct predictions: {correct_predictions} out of {len(examples)}')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 Persian text examples with their true genres\n",
    "examples = [\n",
    "    (\"Ø³Ø§Ø±Ø§ Ø¯Ø± ØªÙ„Ø§Ø´ Ø§Ø³Øª ØªØ§ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ø­Ø±Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ Ùˆ Ù…Ø´Ú©Ù„Ø§Øª Ø´Ø®ØµÛŒâ€ŒØ§Ø´ Ø²Ù†Ø¯Ú¯ÛŒ Ø¨Ù‡ØªØ±ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ±Ø²Ù†Ø¯Ø§Ù†Ø´ ÙØ±Ø§Ù‡Ù… Ú©Ù†Ø¯.\", \"Drama\"),\n",
    "    (\"Ú©Ø§Ù…Ø±Ø§Ù† ØªØµÙ…ÛŒÙ… Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯ Ú©Ù‡ Ù¾Ø³ Ø§Ø² Ø¨Ø§Ø²Ù†Ø´Ø³ØªÚ¯ÛŒ Ø¨Ù‡ Ø´Ù‡Ø± Ø²Ø§Ø¯Ú¯Ø§Ù‡Ø´ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø¯ Ùˆ Ø®Ø§Ù†Ù‡ Ú©ÙˆØ¯Ú©ÛŒâ€ŒØ§Ø´ Ø±Ø§ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ú©Ù†Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ú©Ù…Ø¯ÛŒÙ† Ø¬ÙˆØ§Ù† Ø¯Ø± ØªÙ„Ø§Ø´ Ø§Ø³Øª ØªØ§ Ø¨Ø§ Ø´ÙˆØ®ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†ÙˆÛŒÙ† Ùˆ Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡ Ø®ÙˆØ¯ Ù…Ø®Ø§Ø·Ø¨Ø§Ù† Ø¨ÛŒØ´ØªØ±ÛŒ Ø¬Ø°Ø¨ Ú©Ù†Ø¯.\", \"Comedy\"),\n",
    "    (\"ÛŒÚ© Ù…Ø¹Ù„Ù… Ù…Ø¯Ø±Ø³Ù‡ Ø±ÙˆØ³ØªØ§ÛŒÛŒ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù†Ø´ Ø±Ø§ Ø¨Ù‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ ØªØ´ÙˆÛŒÙ‚ Ú©Ù†Ø¯ Ùˆ Ø¢ÛŒÙ†Ø¯Ù‡ Ø¨Ù‡ØªØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù†Ù‡Ø§ Ø±Ù‚Ù… Ø¨Ø²Ù†Ø¯.\", \"Drama\"),\n",
    "    (\"Ù…Ø±ÛŒÙ… Ùˆ Ø¹Ù„ÛŒ ØªØµÙ…ÛŒÙ… Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯ Ú©Ù‡ Ø¯Ø± ÛŒÚ© Ø³ÙØ± Ù…Ø§Ø¬Ø±Ø§Ø¬ÙˆÛŒØ§Ù†Ù‡ Ø¨Ù‡ Ú©ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§Ù„ Ú©Ø´ÙˆØ± Ø¨Ø±ÙˆÙ†Ø¯ Ùˆ Ø¯Ø± Ø§ÛŒÙ† Ø³ÙØ± Ø¨Ø§ Ø§ØªÙØ§Ù‚Ø§Øª Ø®Ù†Ø¯Ù‡â€ŒØ¯Ø§Ø±ÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.\", \"Comedy\"),\n",
    "    (\"ÛŒÚ© Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø§Ø² Ø¯Ø§Ø³ØªØ§Ù†â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø²Ù†Ø¯Ú¯ÛŒ Ù…Ø±Ø¯Ù… ÛŒÚ© Ú©ØªØ§Ø¨ Ø§Ù„Ù‡Ø§Ù…â€ŒØ¨Ø®Ø´ Ø¨Ù†ÙˆÛŒØ³Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ú¯Ø±ÙˆÙ‡ Ù…ÙˆØ³ÛŒÙ‚ÛŒ ØªØµÙ…ÛŒÙ… Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯ ØªØ§ Ø¯Ø± ÛŒÚ© ÙØ³ØªÛŒÙˆØ§Ù„ Ø¨Ø²Ø±Ú¯ Ø´Ø±Ú©Øª Ú©Ù†Ù†Ø¯ Ùˆ Ø¯Ø± Ø§ÛŒÙ† Ø±Ø§Ù‡ Ø¨Ø§ Ù…Ø´Ú©Ù„Ø§Øª Ùˆ Ø§ØªÙØ§Ù‚Ø§Øª Ø®Ù†Ø¯Ù‡â€ŒØ¯Ø§Ø±ÛŒ Ø±ÙˆØ¨Ø±Ùˆ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.\", \"Comedy\"),\n",
    "    (\"ÛŒÚ© Ø¨Ø§Ø²ÛŒÚ¯Ø± Ù…Ø´Ù‡ÙˆØ± Ø¨Ø§ Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ÛŒ Ø´Ù‡Ø±Øª Ùˆ ÙØ´Ø§Ø±Ù‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ø±ÙˆØ¨Ø±Ùˆ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø²Ù†Ø¯Ú¯ÛŒ Ø´Ø®ØµÛŒâ€ŒØ§Ø´ Ø±Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù†Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ù¾Ø³Ø± Ù†ÙˆØ¬ÙˆØ§Ù† Ú©Ù‡ Ø¨Ù‡ ØªØ§Ø²Ú¯ÛŒ ÙˆØ§Ø±Ø¯ Ø¯Ø¨ÛŒØ±Ø³ØªØ§Ù† Ø´Ø¯Ù‡ Ø§Ø³Øª Ø¨Ø§ Ù…Ø´Ú©Ù„Ø§Øª Ø¬Ø¯ÛŒØ¯ Ùˆ Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ù„ÙˆØº Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ø²Ù† Ùˆ Ø´ÙˆÙ‡Ø± ØªØµÙ…ÛŒÙ… Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯ ØªØ§ Ú©Ø³Ø¨ Ùˆ Ú©Ø§Ø± Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ú¯Ø³ØªØ±Ø´ Ø¯Ù‡Ù†Ø¯ Ùˆ Ø¯Ø± Ø§ÛŒÙ† Ø±Ø§Ù‡ Ø¨Ø§ Ù…Ø´Ú©Ù„Ø§Øª Ø®Ù†Ø¯Ù‡â€ŒØ¯Ø§Ø±ÛŒ Ø±ÙˆØ¨Ø±Ùˆ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.\", \"Comedy\"),\n",
    "    (\"ÛŒÚ© Ø²Ù† Ø¬ÙˆØ§Ù† ØªØµÙ…ÛŒÙ… Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯ Ú©Ù‡ Ù¾Ø³ Ø§Ø² Ø´Ú©Ø³Øª Ø¹Ø´Ù‚ÛŒ Ø¨Ø²Ø±Ú¯ Ø¨Ù‡ Ø³ÙØ± Ø¨Ø±ÙˆØ¯ Ùˆ Ø¯Ø± Ø§ÛŒÙ† Ø³ÙØ± Ø¨Ø§ Ø®ÙˆØ¯Ø¢Ú¯Ø§Ù‡ÛŒ Ø¨ÛŒØ´ØªØ±ÛŒ Ø±ÙˆØ¨Ø±Ùˆ Ø´ÙˆØ¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ù¾Ø¯Ø± ØªÙ†Ù‡Ø§ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø¨Ø±Ø§ÛŒ Ø¯Ø®ØªØ± Ú©ÙˆÚ†Ú©Ø´ ÛŒÚ© Ø¬Ø´Ù† ØªÙˆÙ„Ø¯ ÙØ±Ø§Ù…ÙˆØ´â€ŒÙ†Ø´Ø¯Ù†ÛŒ Ø¨Ø±Ú¯Ø²Ø§Ø± Ú©Ù†Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ú©Ø§Ø±Ø¢Ú¯Ø§Ù‡ Ø®ØµÙˆØµÛŒ Ø¯Ø± ØªÙ„Ø§Ø´ Ø§Ø³Øª ØªØ§ Ù¾Ø±ÙˆÙ†Ø¯Ù‡ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ ÛŒÚ© Ù‚ØªÙ„ Ø±Ø§ Ø­Ù„ Ú©Ù†Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ø§Ø³ØªØ§Ø¯ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø¨Ø§ ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ Ø¬Ø¯ÛŒØ¯ Ùˆ Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø¹Ù„Ù…ÛŒ Ø®ÙˆØ¯ Ù¾ÛŒØ´Ø±ÙØª Ú©Ù†Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ø²Ù† Ø¬ÙˆØ§Ù† Ø¯Ø± ØªÙ„Ø§Ø´ Ø§Ø³Øª ØªØ§ ÛŒÚ© Ø´Ø±Ú©Øª Ø§Ø³ØªØ§Ø±ØªØ§Ù¾ÛŒ Ù…ÙˆÙÙ‚ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ù†Ø¯ Ùˆ Ø¨Ø§ Ù…Ø´Ú©Ù„Ø§Øª Ø²ÛŒØ§Ø¯ÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ú¯Ø±ÙˆÙ‡ Ø§Ø² Ø¯ÙˆØ³ØªØ§Ù† ØªØµÙ…ÛŒÙ… Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯ Ú©Ù‡ ØªØ¹Ø·ÛŒÙ„Ø§Øª Ø®ÙˆØ¯ Ø±Ø§ Ø¯Ø± ÛŒÚ© ÙˆÛŒÙ„Ø§ Ø¯Ø± Ø´Ù…Ø§Ù„ Ú©Ø´ÙˆØ± Ø¨Ú¯Ø°Ø±Ø§Ù†Ù†Ø¯ Ùˆ Ø¨Ø§ Ù…Ø§Ø¬Ø±Ø§Ù‡Ø§ÛŒ Ø®Ù†Ø¯Ù‡â€ŒØ¯Ø§Ø±ÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.\", \"Comedy\"),\n",
    "    (\"ÛŒÚ© Ù‡Ù†Ø±Ù…Ù†Ø¯ Ø¬ÙˆØ§Ù† Ø¯Ø± ØªÙ„Ø§Ø´ Ø§Ø³Øª ØªØ§ Ø§ÙˆÙ„ÛŒÙ† Ù†Ù…Ø§ÛŒØ´Ú¯Ø§Ù‡ Ù‡Ù†Ø±ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø±Ú¯Ø²Ø§Ø± Ú©Ù†Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ù…Ø±Ø¨ÛŒ ÙÙˆØªØ¨Ø§Ù„ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ ØªÛŒÙ… Ø¬ÙˆØ§Ù†Ø§Ù† Ù…Ø­Ù„ÛŒ Ø±Ø§ Ø¨Ù‡ Ù‚Ù‡Ø±Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø³Ø§Ù†Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ø²ÙˆØ¬ Ù…Ø³Ù† ØªØµÙ…ÛŒÙ… Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯ ØªØ§ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ Ø²Ù†Ø¯Ú¯ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡ Ø³ÙØ±Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ú¯Ø°Ø±Ø§Ù†Ù†Ø¯ Ùˆ Ø¯Ø± Ù‡Ø± Ø³ÙØ± Ø¨Ø§ Ø§ØªÙØ§Ù‚Ø§Øª Ø®Ù†Ø¯Ù‡â€ŒØ¯Ø§Ø±ÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.\", \"Comedy\"),\n",
    "    (\"ÛŒÚ© Ù…Ø®ØªØ±Ø¹ Ø¬ÙˆØ§Ù† Ø¯Ø± ØªÙ„Ø§Ø´ Ø§Ø³Øª ØªØ§ Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†ÙˆØ¢ÙˆØ±Ø§Ù†Ù‡ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡ ÙˆØ§Ù‚Ø¹ÛŒØª ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ø¯Ø®ØªØ± Ø¬ÙˆØ§Ù† Ú©Ù‡ Ø¨Ù‡ ØªØ§Ø²Ú¯ÛŒ Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ÙØ§Ø±Øºâ€ŒØ§Ù„ØªØ­ØµÛŒÙ„ Ø´Ø¯Ù‡ Ø§Ø³ØªØŒ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø´ØºÙ„ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ù¾ÛŒØ¯Ø§ Ú©Ù†Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ø¯Ø± ØªÙ„Ø§Ø´ Ø§Ø³Øª ØªØ§ Ø¨Ø§ Ø§Ù„Ù‡Ø§Ù… Ø§Ø² Ø²Ù†Ø¯Ú¯ÛŒ Ø®ÙˆØ¯ ÛŒÚ© Ø±Ù…Ø§Ù† Ù¾Ø±ÙØ±ÙˆØ´ Ø¨Ù†ÙˆÛŒØ³Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ú¯Ø±ÙˆÙ‡ Ø§Ø² Ø¯ÙˆØ³ØªØ§Ù† ØªØµÙ…ÛŒÙ… Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯ Ú©Ù‡ ÛŒÚ© Ø±Ø³ØªÙˆØ±Ø§Ù† Ú©ÙˆÚ†Ú© Ø§ÙØªØªØ§Ø­ Ú©Ù†Ù†Ø¯ Ùˆ Ø¯Ø± Ø§ÛŒÙ† Ø±Ø§Ù‡ Ø¨Ø§ Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ÛŒ Ø®Ù†Ø¯Ù‡â€ŒØ¯Ø§Ø±ÛŒ Ø±ÙˆØ¨Ø±Ùˆ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.\", \"Comedy\"),\n",
    "    (\"ÛŒÚ© Ù…Ø§Ø¯Ø± Ø¬ÙˆØ§Ù† ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ù‡Ù…Ø²Ù…Ø§Ù† Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø§Ù†Ù‡ Ùˆ Ø´ØºÙ„ØŒ Ø§Ø² Ú©ÙˆØ¯Ú©Ø§Ù†Ø´ Ù…Ø±Ø§Ù‚Ø¨Øª Ú©Ù†Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ù…Ø¹Ù„Ù… Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø¯Ø± ØªÙ„Ø§Ø´ Ø§Ø³Øª ØªØ§ Ø§Ø³ØªØ¹Ø¯Ø§Ø¯Ù‡Ø§ÛŒ Ù†Ù‡ÙØªÙ‡ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù†Ø´ Ø±Ø§ Ú©Ø´Ù Ùˆ Ù¾Ø±ÙˆØ±Ø´ Ø¯Ù‡Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ø²Ù† ØªØµÙ…ÛŒÙ… Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯ ØªØ§ Ù¾Ø³ Ø§Ø² Ø¬Ø¯Ø§ÛŒÛŒ Ø§Ø² Ù‡Ù…Ø³Ø±Ø´ØŒ Ø²Ù†Ø¯Ú¯ÛŒ Ø¬Ø¯ÛŒØ¯ÛŒ Ø±Ø§ Ø¢ØºØ§Ø² Ú©Ù†Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ú¯Ø±ÙˆÙ‡ ØªØ¦Ø§ØªØ± Ø¢Ù…Ø§ØªÙˆØ± Ø¯Ø± ØªÙ„Ø§Ø´ Ø§Ø³Øª ØªØ§ ÛŒÚ© Ù†Ù…Ø§ÛŒØ´ Ø¨Ø²Ø±Ú¯ Ø±Ø§ Ø±ÙˆÛŒ ØµØ­Ù†Ù‡ Ø¨Ø¨Ø±Ù†Ø¯ Ùˆ Ø¨Ø§ Ù…Ø´Ú©Ù„Ø§Øª Ùˆ Ù…Ø§Ø¬Ø±Ø§Ù‡Ø§ÛŒ Ø®Ù†Ø¯Ù‡â€ŒØ¯Ø§Ø±ÛŒ Ø±ÙˆØ¨Ø±Ùˆ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.\", \"Comedy\"),\n",
    "    (\"ÛŒÚ© Ù¾Ø³Ø± Ù†ÙˆØ¬ÙˆØ§Ù† Ú©Ù‡ Ø¨Ù‡ ØªØ§Ø²Ú¯ÛŒ Ø¨Ù‡ Ø´Ù‡Ø± Ø¬Ø¯ÛŒØ¯ÛŒ Ù†Ù‚Ù„ Ù…Ú©Ø§Ù† Ú©Ø±Ø¯Ù‡ Ø§Ø³ØªØŒ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø¯ÙˆØ³ØªØ§Ù† Ø¬Ø¯ÛŒØ¯ Ù¾ÛŒØ¯Ø§ Ú©Ù†Ø¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© ÙˆØ±Ø²Ø´Ú©Ø§Ø± Ø¬ÙˆØ§Ù† ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø¨Ù‡ ØªÛŒÙ… Ù…Ù„ÛŒ Ú©Ø´ÙˆØ±Ø´ Ø±Ø§Ù‡ Ù¾ÛŒØ¯Ø§ Ú©Ù†Ø¯ Ùˆ Ø¯Ø± Ø§ÛŒÙ† Ø±Ø§Ù‡ Ø¨Ø§ Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ§Ø¯ÛŒ Ø±ÙˆØ¨Ø±Ùˆ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\", \"Drama\"),\n",
    "    (\"ÛŒÚ© Ø²Ù† Ùˆ Ù…Ø±Ø¯ Ø¯Ø± ÛŒÚ© Ù…Ø§Ø¬Ø±Ø§ÛŒ Ø¹Ø´Ù‚ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯ Ùˆ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ ØªØ§ Ù…ÙˆØ§Ù†Ø¹ Ø±Ø§ Ù¾Ø´Øª Ø³Ø± Ø¨Ú¯Ø°Ø§Ø±Ù†Ø¯.\", \"Drama\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genre(text, model, tokenizer):\n",
    "    model.eval()\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predicted_class_idx = logits.argmax(axis=1).item()\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_class_idx])[0]\n",
    "    \n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted genres: ['Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama']\n",
      "True genres: ['Drama', 'Drama', 'Comedy', 'Drama', 'Comedy', 'Drama', 'Comedy', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama', 'Comedy', 'Drama', 'Drama', 'Drama']\n",
      "Number of correct predictions: 28 out of 30\n",
      "Accuracy: 0.93\n",
      "F1 Score (Macro): 0.91\n",
      "F1 Score (Micro): 0.93\n",
      "Precision (Macro): 0.91\n",
      "Recall (Macro): 0.91\n",
      "Confusion Matrix:\n",
      "[[ 7  1]\n",
      " [ 1 21]]\n"
     ]
    }
   ],
   "source": [
    "# Predict genres for the examples\n",
    "true_labels = [genre for _, genre in examples]\n",
    "predicted_labels = [predict_genre(text, model, tokenizer) for text, _ in examples]\n",
    "\n",
    "# Evaluate accuracy\n",
    "correct_predictions = sum([true == pred for true, pred in zip(true_labels, predicted_labels)])\n",
    "accuracy = correct_predictions / len(examples)\n",
    "\n",
    "print(f'Predicted genres: {predicted_labels}')\n",
    "print(f'True genres: {true_labels}')\n",
    "print(f'Number of correct predictions: {correct_predictions} out of {len(examples)}')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Calculate and print additional metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "f1_macro = f1_score(true_labels, predicted_labels, average='macro')\n",
    "f1_micro = f1_score(true_labels, predicted_labels, average='micro')\n",
    "precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "print(f'F1 Score (Macro): {f1_macro:.2f}')\n",
    "print(f'F1 Score (Micro): {f1_micro:.2f}')\n",
    "print(f'Precision (Macro): {precision:.2f}')\n",
    "print(f'Recall (Macro): {recall:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
