{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Head:\n",
      "                                                 Link            EN_title  \\\n",
      "0  https://www.imvbox.com/watch-persian-movie-ira...   Local Anaesthetic   \n",
      "1  https://www.imvbox.com/watch-persian-movie-ira...         Disturbance   \n",
      "2  https://www.imvbox.com/watch-persian-movie-ira...           Highlight   \n",
      "3  https://www.imvbox.com/watch-persian-movie-ira...               Gilda   \n",
      "4  https://www.imvbox.com/watch-persian-movie-ira...  Atmosphere Station   \n",
      "\n",
      "     PENGLISH_title   PERSIAN_title  \\\n",
      "0  Bi Hessie Mozeie    Ø¨ÛŒâ€ŒØ­Ø³ÛŒ Ù…ÙˆØ¶Ø¹ÛŒ   \n",
      "1         Ashoftegi        Ø¢Ø´ÙØªÙ‡ Ú¯ÛŒ   \n",
      "2           Haylayt         Ù‡Ø§ÛŒÙ„Ø§ÛŒØª   \n",
      "3            Geelda           Ú¯ÛŒÙ„Ø¯Ø§   \n",
      "4  Istgahe Atmosfer  Ø§ÛŒØ³ØªÚ¯Ø§Ù‡ Ø§ØªÙ…Ø³ÙØ±   \n",
      "\n",
      "                                           Content_1  \\\n",
      "0  Ø¬Ù„Ø§Ù„â€ŒØŒ Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒ Ø³Ø§Ø¨Ù‚ Ø±Ø´ØªÙ‡ ÙÙ„Ø³ÙÙ‡ØŒ Ù…ØªÙˆØ¬Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø®...   \n",
      "1  Â«Ø¢Ø´ÙØªÙ‡â€ŒÚ¯ÛŒÂ» Ø±Ø¦Ø§Ù„ÛŒØ³ØªÛŒ Ùˆ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ù†ÛŒØ³Øª. ÛŒÚ© ÙÛŒÙ„Ù… Ø§Ø³...   \n",
      "2  ÛŒÚ© ØªØµØ§Ø¯Ù Ø§ØªÙˆÙ…Ø¨ÛŒÙ„ Ø¢Ø¯Ù…â€ŒÙ‡Ø§ÛŒÛŒ Ø±Ø§ Ø¯Ø± ØªÙ‚Ø§Ø¨Ù„ Ø¨Ø§ Ù‡Ù… Ù‚Ø±...   \n",
      "3  Ú¯ÛŒÙ„Ø¯Ø§ Ù…Ø§Ø¬Ø±Ø§ÛŒ Ø²Ù†ÛŒ Ø¨Ù‡ Ù†Ø§Ù… Â«Ú¯ÛŒÙ„Ø¯Ø§Â» Ø±Ø§ Ø±ÙˆØ§ÛŒØª Ù…ÛŒ Ú©Ù†...   \n",
      "4  Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø±ÙˆØ§ÛŒØª Ú¯Ø± Ø¯Ø§Ø³ØªØ§Ù† Ø²Ù†Ø¯Ú¯ÛŒ Ø²ÙˆØ¬ Ø¬ÙˆØ§Ù†ÛŒ Ø¨Ù‡ Ø§Ø³...   \n",
      "\n",
      "                                           Content_2  Score  Year  Genre Time  \n",
      "0  Jalal, a dropouts philosophy student, realizes...    4.8  2018  Drama   73  \n",
      "1  After the murder of his rich twin brother, Bar...    3.8  2018  Crime   78  \n",
      "2  A man and a woman are have a car accident and ...    4.4  2017  Drama   77  \n",
      "3  Gilda who owns a restaurant has a terrible nig...    3.8  2018  Drama   79  \n",
      "4  Vahid and Marjan are a young couple who have g...    5.6  2017  Drama   85  \n",
      "Columns:\n",
      " Index(['Link', 'EN_title', 'PENGLISH_title', 'PERSIAN_title', 'Content_1',\n",
      "       'Content_2', 'Score', 'Year', 'Genre', 'Time'],\n",
      "      dtype='object')\n",
      "Missing Values:\n",
      " Link                0\n",
      "EN_title            0\n",
      "PENGLISH_title      5\n",
      "PERSIAN_title       1\n",
      "Content_1         361\n",
      "Content_2         206\n",
      "Score               0\n",
      "Year                0\n",
      "Genre               0\n",
      "Time                8\n",
      "dtype: int64\n",
      "Cleaned DataFrame Head:\n",
      "                                                 Link            EN_title  \\\n",
      "0  https://www.imvbox.com/watch-persian-movie-ira...   Local Anaesthetic   \n",
      "1  https://www.imvbox.com/watch-persian-movie-ira...         Disturbance   \n",
      "2  https://www.imvbox.com/watch-persian-movie-ira...           Highlight   \n",
      "3  https://www.imvbox.com/watch-persian-movie-ira...               Gilda   \n",
      "4  https://www.imvbox.com/watch-persian-movie-ira...  Atmosphere Station   \n",
      "\n",
      "     PENGLISH_title   PERSIAN_title  \\\n",
      "0  Bi Hessie Mozeie    Ø¨ÛŒâ€ŒØ­Ø³ÛŒ Ù…ÙˆØ¶Ø¹ÛŒ   \n",
      "1         Ashoftegi        Ø¢Ø´ÙØªÙ‡ Ú¯ÛŒ   \n",
      "2           Haylayt         Ù‡Ø§ÛŒÙ„Ø§ÛŒØª   \n",
      "3            Geelda           Ú¯ÛŒÙ„Ø¯Ø§   \n",
      "4  Istgahe Atmosfer  Ø§ÛŒØ³ØªÚ¯Ø§Ù‡ Ø§ØªÙ…Ø³ÙØ±   \n",
      "\n",
      "                                           Content_1  \\\n",
      "0  Ø¬Ù„Ø§Ù„â€ŒØŒ Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒ Ø³Ø§Ø¨Ù‚ Ø±Ø´ØªÙ‡ ÙÙ„Ø³ÙÙ‡ØŒ Ù…ØªÙˆØ¬Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø®...   \n",
      "1  Â«Ø¢Ø´ÙØªÙ‡â€ŒÚ¯ÛŒÂ» Ø±Ø¦Ø§Ù„ÛŒØ³ØªÛŒ Ùˆ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ù†ÛŒØ³Øª. ÛŒÚ© ÙÛŒÙ„Ù… Ø§Ø³...   \n",
      "2  ÛŒÚ© ØªØµØ§Ø¯Ù Ø§ØªÙˆÙ…Ø¨ÛŒÙ„ Ø¢Ø¯Ù…â€ŒÙ‡Ø§ÛŒÛŒ Ø±Ø§ Ø¯Ø± ØªÙ‚Ø§Ø¨Ù„ Ø¨Ø§ Ù‡Ù… Ù‚Ø±...   \n",
      "3  Ú¯ÛŒÙ„Ø¯Ø§ Ù…Ø§Ø¬Ø±Ø§ÛŒ Ø²Ù†ÛŒ Ø¨Ù‡ Ù†Ø§Ù… Â«Ú¯ÛŒÙ„Ø¯Ø§Â» Ø±Ø§ Ø±ÙˆØ§ÛŒØª Ù…ÛŒ Ú©Ù†...   \n",
      "4  Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø±ÙˆØ§ÛŒØª Ú¯Ø± Ø¯Ø§Ø³ØªØ§Ù† Ø²Ù†Ø¯Ú¯ÛŒ Ø²ÙˆØ¬ Ø¬ÙˆØ§Ù†ÛŒ Ø¨Ù‡ Ø§Ø³...   \n",
      "\n",
      "                                           Content_2  Score  Year  Genre Time  \n",
      "0  Jalal, a dropouts philosophy student, realizes...    4.8  2018  Drama   73  \n",
      "1  After the murder of his rich twin brother, Bar...    3.8  2018  Crime   78  \n",
      "2  A man and a woman are have a car accident and ...    4.4  2017  Drama   77  \n",
      "3  Gilda who owns a restaurant has a terrible nig...    3.8  2018  Drama   79  \n",
      "4  Vahid and Marjan are a young couple who have g...    5.6  2017  Drama   85  \n",
      "Encoded Labels:\n",
      " 0    7\n",
      "1    5\n",
      "2    7\n",
      "3    7\n",
      "4    7\n",
      "Name: Genre_encoded, dtype: int32\n",
      "Training Set Size: 860\n",
      "Validation Set Size: 108\n",
      "Test Set Size: 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688971a48c6141169cd40862a46bb094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0678, 'grad_norm': 17.206127166748047, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.09}\n",
      "{'loss': 3.0929, 'grad_norm': 16.972537994384766, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.19}\n",
      "{'loss': 3.033, 'grad_norm': 15.99864673614502, 'learning_rate': 3e-06, 'epoch': 0.28}\n",
      "{'loss': 2.8632, 'grad_norm': 16.496543884277344, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.37}\n",
      "{'loss': 2.8659, 'grad_norm': 20.564659118652344, 'learning_rate': 5e-06, 'epoch': 0.46}\n",
      "{'loss': 2.7995, 'grad_norm': 18.60843276977539, 'learning_rate': 6e-06, 'epoch': 0.56}\n",
      "{'loss': 2.8122, 'grad_norm': 28.743831634521484, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.65}\n",
      "{'loss': 2.8848, 'grad_norm': 18.807851791381836, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.74}\n",
      "{'loss': 2.7629, 'grad_norm': 30.592498779296875, 'learning_rate': 9e-06, 'epoch': 0.83}\n",
      "{'loss': 2.626, 'grad_norm': 20.519529342651367, 'learning_rate': 1e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bd9e87114f44d9929fabbb3fd806e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.678762912750244, 'eval_runtime': 81.0766, 'eval_samples_per_second': 1.332, 'eval_steps_per_second': 0.173, 'epoch': 1.0}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"The `metric_for_best_model` training argument is set to 'eval_f1', which is not found in the evaluation metrics. The available evaluation metrics are: ['eval_loss', 'eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'epoch']. Consider changing the `metric_for_best_model` via the TrainingArguments.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:2889\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[1;34m(self, model, trial, metrics)\u001b[0m\n\u001b[0;32m   2888\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2889\u001b[0m     metric_value \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric_to_check\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'eval_f1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 133\u001b[0m\n\u001b[0;32m    123\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CustomTrainer(\n\u001b[0;32m    124\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    125\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Add your custom metrics computation here\u001b[39;00m\n\u001b[0;32m    130\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m    136\u001b[0m results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(test_dataset)\n",
      "File \u001b[1;32mc:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:2365\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 2365\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m   2368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[0;32m   2369\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:2796\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2793\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(trial, ignore_keys_for_eval)\n\u001b[0;32m   2795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m-> 2796\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[1;32mc:\\Users\\Fateme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:2891\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[1;34m(self, model, trial, metrics)\u001b[0m\n\u001b[0;32m   2889\u001b[0m     metric_value \u001b[38;5;241m=\u001b[39m metrics[metric_to_check]\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m-> 2891\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m   2892\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `metric_for_best_model` training argument is set to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_to_check\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, which is not found in the evaluation metrics. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2893\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe available evaluation metrics are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider changing the `metric_for_best_model` via the TrainingArguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2894\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m   2896\u001b[0m operator \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgreater \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgreater_is_better \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mless\n\u001b[0;32m   2897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_metric \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2899\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_model_checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2900\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m operator(metric_value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_metric)\n\u001b[0;32m   2901\u001b[0m ):\n",
      "\u001b[1;31mKeyError\u001b[0m: \"The `metric_for_best_model` training argument is set to 'eval_f1', which is not found in the evaluation metrics. The available evaluation metrics are: ['eval_loss', 'eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'epoch']. Consider changing the `metric_for_best_model` via the TrainingArguments.\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = 'dataset.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Display dataset information\n",
    "print(\"DataFrame Head:\\n\", df.head())\n",
    "print(\"Columns:\\n\", df.columns)\n",
    "print(\"Missing Values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Ensure 'Content_1' and 'Genre' columns are present\n",
    "if 'Content_1' not in df.columns or 'Genre' not in df.columns:\n",
    "    raise ValueError(\"Required columns 'Content_1' or 'Genre' are missing in the dataframe.\")\n",
    "\n",
    "# Drop rows with missing 'Content_1' or 'Genre'\n",
    "df = df.dropna(subset=['Content_1', 'Genre'])\n",
    "\n",
    "# Reset index to ensure proper indexing\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows after cleaning\n",
    "print(\"Cleaned DataFrame Head:\\n\", df.head())\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['Genre_encoded'] = label_encoder.fit_transform(df['Genre'])\n",
    "\n",
    "# Display encoded labels\n",
    "print(\"Encoded Labels:\\n\", df['Genre_encoded'].head())\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_df, val_df, test_df = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "# Check the splits\n",
    "print(f\"Training Set Size: {len(train_df)}\")\n",
    "print(f\"Validation Set Size: {len(val_df)}\")\n",
    "print(f\"Test Set Size: {len(test_df)}\")\n",
    "\n",
    "# Initialize ParsBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('HooshvareLab/bert-fa-base-uncased')\n",
    "\n",
    "# Custom dataset class for Persian summaries\n",
    "class PersianMovieGenreDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts.reset_index(drop=True)  # Ensure proper indexing\n",
    "        self.labels = labels.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PersianMovieGenreDataset(train_df['Content_1'], train_df['Genre_encoded'], tokenizer)\n",
    "val_dataset = PersianMovieGenreDataset(val_df['Content_1'], val_df['Genre_encoded'], tokenizer)\n",
    "test_dataset = PersianMovieGenreDataset(test_df['Content_1'], test_df['Genre_encoded'], tokenizer)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_df['Genre_encoded']), y=train_df['Genre_encoded'])\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "# Convert class weights to tensor\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# Load the ParsBERT model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('HooshvareLab/bert-fa-base-uncased', num_labels=len(label_encoder.classes_))\n",
    "model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# Define custom training arguments with class weights\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",  # Ensure both evaluation and save strategy are the same\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1'\n",
    ")\n",
    "\n",
    "# Custom Trainer class to handle class weights\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_tensor.to(logits.device))\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=None  # Add your custom metrics computation here\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "results = trainer.evaluate(test_dataset)\n",
    "print(results)\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model.save_pretrained('./parsbert_movie_genre_classifier')\n",
    "tokenizer.save_pretrained('./parsbert_movie_genre_classifier')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
